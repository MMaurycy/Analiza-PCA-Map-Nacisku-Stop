# Analiza GÅ‚Ã³wnych SkÅ‚adowych (PCA) dla Zbioru Map Nacisku StÃ³p

**Autor:** Marcin Przybylski
**Data:** 2 maja 2025

## Opis Projektu

Niniejszy projekt przedstawia analizÄ™ zbioru danych map nacisku stÃ³p przy uÅ¼yciu metody Analizy GÅ‚Ã³wnych SkÅ‚adowych (Principal Component Analysis - PCA). Celem byÅ‚o zrozumienie i praktyczne zastosowanie PCA do analizy rzeczywistego zbioru danych biomedycznych, skÅ‚adajÄ…cego siÄ™ z obrazÃ³w reprezentujÄ…cych rozkÅ‚ad nacisku stopy na podÅ‚oÅ¼e, pochodzÄ…cych z pomiarÃ³w dla rÃ³Å¼nych pozycji ciaÅ‚a (przysiad, skÅ‚on, stanie).

GÅ‚Ã³wne cele analizy obejmowaÅ‚y:
* Zrozumienie struktury danych i podstawowych charakterystyk zbioru map nacisku stÃ³p.
* Zastosowanie PCA do redukcji wymiarowoÅ›ci danych, przy zachowaniu maksymalnej iloÅ›ci informacji (wariancji).
* WizualizacjÄ™ gÅ‚Ã³wnych skÅ‚adowych ("Eigenfeet") w celu zrozumienia gÅ‚Ã³wnych kierunkÃ³w zmiennoÅ›ci w danych.
* OcenÄ™ jakoÅ›ci rekonstrukcji danych na podstawie zredukowanej reprezentacji.
* IdentyfikacjÄ™ najbardziej charakterystycznych (najbardziej rÃ³Å¼niÄ…cych siÄ™ od siebie) map nacisku stÃ³p w zbiorze za pomocÄ… analizy odlegÅ‚oÅ›ci w przestrzeni PCA.

## ğŸ“‚ Zasoby Projektu

Prace zostaÅ‚y zrealizowane w Å›rodowisku Google Colaboratory.

## ğŸ”¬ Podstawy Teoretyczne PCA

Analiza GÅ‚Ã³wnych SkÅ‚adowych (PCA) to technika statystyczna i algorytm uczenia maszynowego bez nadzoru, stosowany gÅ‚Ã³wnie do redukcji wymiarowoÅ›ci. DziaÅ‚a poprzez transformacjÄ™ liniowÄ… oryginalnych, potencjalnie skorelowanych zmiennych, w nowy zestaw nieskorelowanych zmiennych (gÅ‚Ã³wnych skÅ‚adowych), uporzÄ…dkowanych malejÄ…co wedÅ‚ug iloÅ›ci wariancji, ktÃ³rÄ… wyjaÅ›niajÄ….

**GÅ‚Ã³wne kroki algorytmu PCA:**
1.  Standaryzacja danych (opcjonalnie, w tym przypadku dane byÅ‚y juÅ¼ wstÄ™pnie przeskalowane).
2.  Obliczenie macierzy kowariancji.
3.  Obliczenie wartoÅ›ci wÅ‚asnych i wektorÃ³w wÅ‚asnych macierzy kowariancji. Wektory wÅ‚asne wskazujÄ… kierunki maksymalnej wariancji, a wartoÅ›ci wÅ‚asne okreÅ›lajÄ… wielkoÅ›Ä‡ tej wariancji.
4.  Sortowanie gÅ‚Ã³wnych skÅ‚adowych wedÅ‚ug malejÄ…cych wartoÅ›ci wÅ‚asnych.
5.  WybÃ³r liczby skÅ‚adowych (k) do zachowania, czÄ™sto na podstawie progu wyjaÅ›nionej wariancji.
6.  Transformacja danych poprzez rzutowanie na nowÄ… podprzestrzeÅ„ zdefiniowanÄ… przez k wybranych wektorÃ³w wÅ‚asnych.

**Zalety PCA:**
* Redukcja wymiarowoÅ›ci.
* Usuwanie korelacji.
* Redukcja szumu.
* Identyfikacja wzorcÃ³w.

**Wady PCA:**
* WraÅ¼liwoÅ›Ä‡ na skalÄ™ zmiennych (wymaga standaryzacji, jeÅ›li skale sÄ… rÃ³Å¼ne).
* GÅ‚Ã³wne skÅ‚adowe mogÄ… byÄ‡ trudne do bezpoÅ›redniej interpretacji.
* ZaÅ‚oÅ¼enie o liniowoÅ›ci.
* Utrata informacji przy redukcji wymiarowoÅ›ci.

## âš™ï¸ Metodologia Analizy

### 1. Wczytywanie i Przygotowanie Danych

* Dane wejÅ›ciowe (mapy nacisku stÃ³p) pobrano jako plik `.npy`.
* Oryginalny ksztaÅ‚t danych: (18, 34, 6588) (wysokoÅ›Ä‡, szerokoÅ›Ä‡, liczba prÃ³bek).
* Zmiana kolejnoÅ›ci wymiarÃ³w do formatu (liczba\_prÃ³bek, wysokoÅ›Ä‡, szerokoÅ›Ä‡): (6588, 18, 34).
* Liczba cech (pikseli) na obraz po spÅ‚aszczeniu: $18 \times 34 = 612$.
* Ostateczny ksztaÅ‚t danych wejÅ›ciowych do PCA (po spÅ‚aszczeniu obrazÃ³w): (6588, 612).

### 2. Implementacja PCA

* Wykorzystano klasÄ™ `PCA` z moduÅ‚u `sklearn.decomposition`.
* **Krok 1:** Utworzenie instancji `PCA(n_components=None)` i dopasowanie do danych w celu analizy wyjaÅ›nionej wariancji przez wszystkie moÅ¼liwe skÅ‚adowe.
* **Krok 2:** Wyznaczenie liczby skÅ‚adowych potrzebnych do wyjaÅ›nienia okreÅ›lonego progu wariancji (np. 95%).
* **Krok 3:** Utworzenie nowej instancji `PCA` z wybranÄ… liczbÄ… skÅ‚adowych i dopasowanie jej.
* **Krok 4:** Transformacja oryginalnych danych do przestrzeni o zredukowanej wymiarowoÅ›ci (`X_stopy_pca`).
* **Krok 5:** Odwrotna transformacja (rekonstrukcja) danych z przestrzeni zredukowanej do przestrzeni oryginalnej (`X_stopy_reconstructed`).

### 3. Identyfikacja Charakterystycznych StÃ³p

* Obliczono odlegÅ‚oÅ›ci euklidesowe miÄ™dzy wszystkimi parami prÃ³bek w przestrzeni o zredukowanej wymiarowoÅ›ci (`X_stopy_pca`) przy uÅ¼yciu `sklearn.metrics.pairwise.euclidean_distances` oraz `scipy.spatial.distance.pdist` i `scipy.spatial.distance.squareform`.
* Zidentyfikowano parÄ™ indeksÃ³w prÃ³bek o najwiÄ™kszej odlegÅ‚oÅ›ci.

## ğŸ› ï¸ Wykorzystane NarzÄ™dzia i Technologie

* **JÄ™zyk programowania:** Python
* **Biblioteki:**
    * NumPy
    * Matplotlib
    * Scikit-learn (`sklearn.decomposition.PCA`, `sklearn.metrics.pairwise.euclidean_distances`)
    * SciPy (`scipy.spatial.distance.pdist`, `scipy.spatial.distance.squareform`)
* **Åšrodowisko:** Google Colaboratory

## ğŸ“Š Wyniki i Interpretacja

### Analiza WyjaÅ›nionej Wariancji

* Stwierdzono, Å¼e znaczÄ…ca czÄ™Å›Ä‡ wariancji jest skoncentrowana w pierwszych kilkudziesiÄ™ciu skÅ‚adowych.
* Do wyjaÅ›nienia 95% caÅ‚kowitej wariancji w zbiorze danych wystarczyÅ‚o zachowaÄ‡ **33 gÅ‚Ã³wne skÅ‚adowe**.
* Po transformacji z uÅ¼yciem 33 skÅ‚adowych, dane miaÅ‚y ksztaÅ‚t (6588, 33).
* DokÅ‚adny procent zachowanej wariancji wyniÃ³sÅ‚ **95.13%**.

### Wizualizacja GÅ‚Ã³wnych SkÅ‚adowych ("Eigenfeet")

* GÅ‚Ã³wne skÅ‚adowe (wektory wÅ‚asne macierzy kowariancji) zostaÅ‚y zwizualizowane poprzez przeksztaÅ‚cenie ich z powrotem do oryginalnych wymiarÃ³w obrazu ($18 \times 34$). Nazwano je "Eigenfeet", analogicznie do "Eigenfaces".
* "Eigenfeet" pokazujÄ… wzorce nacisku, ktÃ³re najbardziej rÃ³Å¼nicujÄ… poszczegÃ³lne prÃ³bki. Pierwsze skÅ‚adowe kodujÄ… globalne cechy, kolejne bardziej subtelne rÃ³Å¼nice.

### Ocena JakoÅ›ci Rekonstrukcji

* PorÃ³wnanie 10 losowo wybranych oryginalnych map nacisku z ich rekonstrukcjami na podstawie 33 gÅ‚Ã³wnych skÅ‚adowych wykazaÅ‚o, Å¼e rekonstrukcje sÄ… bardzo zbliÅ¼one do oryginaÅ‚Ã³w.
* GÅ‚Ã³wne cechy rozkÅ‚adu nacisku zostaÅ‚y dobrze zachowane, potwierdzajÄ…c, Å¼e 33 gÅ‚Ã³wne skÅ‚adowe wystarczajÄ… do reprezentowania wiÄ™kszoÅ›ci istotnych informacji.

### Identyfikacja Najbardziej Charakterystycznych StÃ³p

* Analiza odlegÅ‚oÅ›ci euklidesowych w przestrzeni PCA (33-wymiarowej) pozwoliÅ‚a zidentyfikowaÄ‡ parÄ™ map nacisku stÃ³p, ktÃ³re najbardziej rÃ³Å¼niÄ… siÄ™ od siebie.
* PorÃ³wnanie wynikÃ³w z funkcji `euclidean_distances` (sklearn) i `pdist` (scipy) wykazaÅ‚o niewielkie rÃ³Å¼nice (prawdopodobnie wynikajÄ…ce z precyzji obliczeÅ„ zmiennoprzecinkowych), ktÃ³re jednak nie wpÅ‚ynÄ™Å‚y na identyfikacjÄ™ pary o maksymalnej odlegÅ‚oÅ›ci.
* NajwiÄ™ksza znaleziona odlegÅ‚oÅ›Ä‡ euklidesowa: **2153.83**.
* OdpowiadajÄ…ca para stÃ³p o oryginalnych indeksach: **1857 i 4308**. Te mapy reprezentujÄ… ekstrema zmiennoÅ›ci w zbiorze danych, uchwycone przez 33 najwaÅ¼niejsze gÅ‚Ã³wne skÅ‚adowe.

## ğŸ Podsumowanie i Wnioski

### Podsumowanie Analizy

Zastosowanie PCA pozwoliÅ‚o na:
1.  **Zbadanie struktury wariancji:** WiÄ™kszoÅ›Ä‡ zmiennoÅ›ci wyjaÅ›niona przez niewielkÄ… liczbÄ™ skÅ‚adowych (33 skÅ‚adowe dla ~95.1% wariancji).
2.  **RedukcjÄ™ wymiarowoÅ›ci:** Z 612 do 33 wymiarÃ³w, przy zachowaniu wiÄ™kszoÅ›ci informacji.
3.  **WizualizacjÄ™ gÅ‚Ã³wnych wzorcÃ³w ("Eigenfeet"):** Zobrazowanie podstawowych wzorcÃ³w zmiennoÅ›ci nacisku stÃ³p.
4.  **OcenÄ™ rekonstrukcji:** Wysoka jakoÅ›Ä‡ rekonstrukcji przy uÅ¼yciu 33 skÅ‚adowych.
5.  **IdentyfikacjÄ™ charakterystycznych stÃ³p:** Znalezienie najbardziej rÃ³Å¼niÄ…cych siÄ™ przypadkÃ³w (indeksy 1857 i 4308).

### Wnioski i WpÅ‚yw WÅ‚asnoÅ›ci PCA

* **SkutecznoÅ›Ä‡ redukcji:** PCA okazaÅ‚o siÄ™ efektywne dla zbioru map nacisku stÃ³p.
* **Interpretacja skÅ‚adowych:** "Eigenfeet" dajÄ… wglÄ…d w kierunki zmiennoÅ›ci, ale ich bezpoÅ›rednia interpretacja fizjologiczna moÅ¼e byÄ‡ trudna.
* **Identyfikacja ekstremÃ³w:** Analiza odlegÅ‚oÅ›ci w przestrzeni PCA pozwala na obiektywne znalezienie nietypowych stÃ³p, co jest przydatne do dalszej analizy i unikania "klÄ…twy wymiarowoÅ›ci".
* **Ograniczenia liniowoÅ›ci:** PCA zakÅ‚ada liniowe zaleÅ¼noÅ›ci. Dla zÅ‚oÅ¼onych, nieliniowych struktur, inne metody (np. t-SNE, UMAP) mogÅ‚yby dostarczyÄ‡ dodatkowych informacji.
* **Zastosowanie w klasyfikacji:** Zredukowane dane mogÄ… byÄ‡ efektywnym wejÅ›ciem do modeli klasyfikacyjnych, potencjalnie przyspieszajÄ…c trening, zmniejszajÄ…c ryzyko przeuczenia i poprawiajÄ…c generalizacjÄ™.

---
